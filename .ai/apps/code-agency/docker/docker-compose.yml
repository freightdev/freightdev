version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: ai-assistant-postgres
    environment:
      POSTGRES_DB: ai_assistant
      POSTGRES_USER: ai_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-change_this_password}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./migrations:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432"
    networks:
      - ai-assistant-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_user -d ai_assistant"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # AI Assistant Backend
  ai-assistant:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-assistant-backend
    environment:
      # Database
      POSTGRES_URL: postgresql+asyncpg://ai_user:${POSTGRES_PASSWORD:-change_this_password}@postgres:5432/ai_assistant
      
      # App settings
      DEBUG: ${DEBUG:-false}
      HOST: 0.0.0.0
      PORT: 8000
      
      # Model settings
      MODELS_DIR: /app/models
      DEFAULT_MODEL: ${DEFAULT_MODEL:-Llama-3.1-8B-Instruct-Q5_K_M.gguf}
      
      # Security
      SECRET_KEY: ${SECRET_KEY:-change_this_super_secret_key}
      
      # Paths
      WORKSPACE_DIR: /app/workspace
      DUCKDB_PATH: /app/data/analytics.duckdb
      LOG_DIR: /app/data/logs
    volumes:
      # Data persistence
      - ai_data:/app/data
      - ai_workspace:/app/workspace
      # Model files (mount your local models directory)
      - ${MODELS_PATH:-./models}:/app/models:ro
      # Configuration
      - ./.env:/app/.env:ro
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - ai-assistant-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 8G

  # GPU-enabled version (uncomment to use)
  # ai-assistant-gpu:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile.gpu
  #   container_name: ai-assistant-gpu
  #   runtime: nvidia
  #   environment:
  #     NVIDIA_VISIBLE_DEVICES: all
  #     CUDA_VISIBLE_DEVICES: 0
  #     # Same environment variables as above...
  #   volumes:
  #     # Same volumes as above...
  #   ports:
  #     - "8000:8000"
  #   depends_on:
  #     postgres:
  #       condition: service_healthy
  #   networks:
  #     - ai-assistant-network
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]

  # Redis (Optional - for caching)
  redis:
    image: redis:7-alpine
    container_name: ai-assistant-redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - ai-assistant-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  # Nginx (Optional - reverse proxy)
  nginx:
    image: nginx:alpine
    container_name: ai-assistant-nginx
    volumes:
      - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - ai-assistant
    networks:
      - ai-assistant-network
    restart: unless-stopped

volumes:
  postgres_data:
    driver: local
  ai_data:
    driver: local
  ai_workspace:
    driver: local
  redis_data:
    driver: local

networks:
  ai-assistant-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16