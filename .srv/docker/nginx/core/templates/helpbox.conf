###########################################
# HELPBOX - AI Machine
# Role = AI/LLM Inference Engine
# Spec = [ CPU = 8T, RAM = 32GB,
#          GPU = CUDA 12.4, VRAM = 4GB ]
# Disk = 1TB SSD (NVMe)
###########################################

#
# Ollama
#
upstream ollama2000 {
    server $HELPBOX_IP:$OLLAMA_PORT;
}

server {
    listen 80;
    server_name ollama2000.$LOCAL_DOMAIN;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl;
    server_name ollama2000.$LOCAL_DOMAIN;

    ssl_certificate /etc/letsencrypt/live/webui.$PUBLIC_DOMAIN/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/webui.$PUBLIC_DOMAIN/privkey.pem;

    location / {
        proxy_pass http://ollama2000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}

#
# Pytorch
#
upstream pytorch2000 {
    server $HELPBOX_IP:$PYTORCH_PORT;
}

server {
    listen 80;
    server_name pytorch1000.$HOST_DOMAIN;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl;
    server_name pytorch1000.$HOST_DOMAIN;

    ssl_certificate /etc/letsencrypt/live/webui.$HOST_DOMAIN/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/webui.$HOST_DOMAIN/privkey.pem;

    location / {
        proxy_pass http://pytorch1000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}
